from packages.tokenizer import tokenize

print(tokenize.get_chinese_stop_words())